{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f49e01ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 932us/step\n",
      "RMSE 0.24008952073326548\n",
      "32/32 [==============================] - 0s 662us/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Flatten, Concatenate, Dot, Reshape, Add, Subtract\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_path = \"./8/\"\n",
    "trval = pd.read_csv(data_path + 'train_sample.csv')\n",
    "test = pd.read_csv(data_path + 'test_sample.csv')\n",
    "feats = [f\"feature_{i}\" for i in range(0, 3)]\n",
    "\n",
    "x_trval, y_trval = trval[feats], trval[\"target\"]\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_trval, y_trval, test_size=0.20, random_state=4, stratify=y_trval)\n",
    "\n",
    "\n",
    "x_train = [x_train[f].values for f in feats]\n",
    "x_val = [x_val[f].values for f in feats]\n",
    "x_test = [test[f].values for f in feats]\n",
    "\n",
    "y_train = y_train.values\n",
    "y_val = y_val.values\n",
    "\n",
    "\n",
    "def get_embed(x_input, x_size, out_dim, embedding_reg=0.0002):\n",
    "    # x_input is index of input (either user or item)\n",
    "    # x_size is length of vocabulary (e.g. total number of users or items)\n",
    "    # out_dim is size of embedding vectors\n",
    "    if x_size > 0: #category\n",
    "        embed = Embedding(x_size, out_dim, input_length=1, embeddings_regularizer=l2(embedding_reg))(x_input)\n",
    "        embed = Flatten()(embed)\n",
    "    else:\n",
    "        embed = Dense(out_dim, kernel_regularizer=l2(embedding_reg))(x_input)\n",
    "    return embed\n",
    "\n",
    "\n",
    "def build_model(f_size, k_latent=2, kernel_reg=0.05):\n",
    "    dim_input = len(f_size)\n",
    "    input_x = [Input(shape=(1, )) for i in range(dim_input)] \n",
    "    lin_terms = [get_embed(x, size, 1) for (x, size) in zip(input_x, f_size)]\n",
    "    factors = [get_embed(x, size, k_latent) for (x, size) in zip(input_x, f_size)]\n",
    "    s = Add()(factors)\n",
    "    diffs = [Subtract()([s, x]) for x in factors]\n",
    "    dots = [Dot(axes=1)([d, x]) for d, x in zip(diffs, factors)]\n",
    "    x = Concatenate()(lin_terms + dots)\n",
    "    x = BatchNormalization()(x)\n",
    "    output = Dense(1, activation='relu', kernel_regularizer=l2(kernel_reg))(x)\n",
    "    model = Model(inputs=input_x, outputs=[output])\n",
    "    model.compile(optimizer=Adam(clipnorm=0.6, learning_rate=0.001), loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "n_epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "f_size = [int(x_trval[f].max()) + 1 for f in feats]\n",
    "model = build_model(f_size)\n",
    "earlystopper = EarlyStopping(patience=20, verbose=0, restore_best_weights=True)\n",
    "model.fit(x_train, y_train, epochs=n_epochs, batch_size=batch_size, verbose=0, validation_data=(x_val, y_val), callbacks=[earlystopper])\n",
    "\n",
    "p = np.squeeze(model.predict(x_val))\n",
    "print(\"RMSE\", mean_squared_error(y_val, p) ** 0.5)\n",
    "\n",
    "preds_test = np.round(np.squeeze(model.predict(x_test))).astype(int)\n",
    "test['target'] = preds_test\n",
    "test.to_csv('submission.csv', index=False, columns=[\"ID\", \"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1e172a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py382",
   "language": "python",
   "name": "py382"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
